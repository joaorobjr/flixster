---
title: "A movies recommender system using Flixster data"
subtitle: "Practical assignment of Advanced Topics in Data Science/Data Mining II"
author: "By Nuno Gomes and Robson Teixeira"
date: "M:DS -- FCUP, 17/05/2020"
output:
  bookdown::pdf_document2:
    #citation_package: natbib
    df_print: tibble
    fig_caption: yes
    fig_crop: no
    fig_height: 5
    fig_width: 7
    number_sections: yes
    toc: yes
  bookdown::html_document2:
    code_folding: "hide"
    df_print: tibble
    fig_caption: yes
    includes:
      in_header: header.html
    number_sections: yes
    theme: cerulean
    toc: yes
    toc_float: yes
geometry:
- top=25mm
- bottom=25mm
- left=25mm
- right=20mm
- heightrounded
header-includes:
  \usepackage{caption}
  \usepackage{fancyhdr}
  \usepackage{lmodern}
  \usepackage[detect-all]{siunitx}
highlight-style: pygments
linkcolor: blue
mainfont: Source Variable Pro
fontsize: 12pt
sansfont: Source Sans Pro
documentclass: report
urlcolor: blue
references:
- id: lesmeister2019
  title: Advanced Machine Learning with R
  author:
    - family: Lesmeister
      given: Cory
    - family: Chinnamgari
      given: Sunil Kumar
  publisher: Packt Publishing Ltd.
  type: book
  issued:
    year: 2019
- id: netflix2009
  title: The Netflix Prize
  URL: https://www.netflixprize.com/
  issued:
    year: 2009
---

```{r setup, include= F}
## include= F prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks.
## echo= F prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures.
## eval= F prevents code to be evaluated.
## message= F prevents messages that are generated by code from appearing in the finished file.
## warning= F prevents warnings that are generated by code from appearing in the finished.
knitr::opts_chunk$set(echo= F, warning= F, message= F)
require(arules)
require(arulesSequences)
require(arulesViz)
require(caret)
require(dplyr)
require(e1071)
require(forcats)
require(funModeling)
require(Hmisc)
require(igraph)
require(lubridate)
require(plotrix)
require(recommenderlab)
require(reshape2)
require(stringr)
require(text2vec)
require(tidyverse)
require(tm)

options(scipen= 999) # turns off scientific notation; to turn it back on, use scipen= 0
```
# Abstract {-}
We report on the methodology we adopted to create a recommendation system for films using the Flixster data set, and on the results we obtained.
Our model is based on the assumption that if a group of users had liked the same films in the past, they will like similar movies in the future.
Hence, if two users have a similar rating history (movies and ratings) and one of them has recently enjoyed a film that the other has not seen yet, then that movie is proposed to the latter.
The recommendation system uniquely takes into account the user ratings, and does not consider the characteristics of the films.
ADD MAIN RESULTS HERE.

# Introduction
**Recommender** or **recommendation** systems are a branch of *Web usage mining* that aim at predicting the "preferences" or the "rating" a user would give to an item.
They are widely used on the Web, mainly in on-line streaming services, such as YouTube, Amazon, or Netflix (just to name a few), and e-commerce applications (eBay, Amazon, OLX, *etc.*), in order to recommend products and services to the users.
They serve three important functions: (*i*) to increase the profit of companies, (*ii*) to help users to select specific products within the available offer, by giving them personalised recommendations based on previous interactions, and (*iii*) to predict the rating for a new item.
Putting it simple, recommendation systems aim at offering the right content to the right customer, at the right time, and through the right channel [@lesmeister2019].
Companies struggle for customer loyalty on a daily basis, and while doing so, they invest on recommender systems that try to increase the likelihood of purchase, by analysing customers' preferences and past interactions.

The importance of recommender systems on the success of businesses and on company-customer relationships can be inferred from the one million dollar prize that Netflix offered in 2006 to the person or team that could improve their recommendation system by at least $10\,\%$ [@netflix2009].
The success of companies such as Amazon or platforms like YouTube lies partly in the recommendation and marketing strategies, based on the user preferences.

During this project, we created a film recommendation system using the Flixster data set, based on binary and non binary approaches, and according to the *item-based collaborative filtering* (IBCF), *user-based collaborative filtering* (UBCF), and *popular* methods.

This report is organised as follows: 

# The Flixster data set
Flixster was an American social-networking on-line service founded by Joe Greenstein and Sarah Chari in 2006.
The platform allowed users to learn about films, to watch trailers, to share their ratings of movies, to discover new films based on their tastes and past views, and to know and meet other users with similar tastes in films.
The company was bought by Fandango in 2016, and the website was shut down in February 2018 in the USA, and October 2019 internationally. 

```{r data, echo= F, error= F}
movies.path= file("../data/movie-names.txt")
profiles.path= file("../data/profile.txt")
ratings.path= file("../data/ratings.timed.txt")

movies.orig= read.delim(movies.path)
profiles.orig= read.csv(
  profiles.path,
  skipNul= T,
  na.strings= c("N/A", "")
)
ratings.orig= read.delim(
  ratings.path,
  sep= "\t",
  skipNul= T, # skip NULL values
  col.names= c("userid", "movieid", "rating", "date")
)
```

The data set used in this study was provided by the Flisxter website, and it can still be found on-line.^[https://sites.google.com/view/mohsenjamali/flixter-data-set]
It consists of $\num{8196077}$ ratings of $\num{48794}$ films by $\num{147612}$ users.
The data are distributed in three files: 

* **movie-names.txt** --- a file containing a collection of \num{66720} film titles and corresponding identification tags;

* **profile.txt** --- a file with \num{1002796} instances, containing general information regarding the users, including user id, gender, age, location, for how long the user has been a member, and the code tags for the last login and the profile view;

* **Ratings.time.txt** --- the aforementioned data set, with \num{8196077} ratings, including the user ID, the movie ID, and the date the rating was registered.

The three data files were loaded into the variables `movies`, `profiles`, and `ratings`, respectively.
A summary of the structure of each of them and a glimpse of their first rows is presented in what follows.

```{r movies-summary, echo= F}
glimpse(movies.orig)
df_status(movies.orig)
head(movies.orig)
```
The previous output represents a glimpse of the `movies` *tibble*, which contains $\num{66730}$ records and two variables (`moviename` and `movieid`) of character and integer types, respectively.
The table contains $\num{66730}$ unique values, with no zeros, no "not availables" (NAs), nor infinite.
In its original form, the `moviename` variable contains html code, which was subsequently removed (see section \@ref(data-cleaning)).

```{r profiles-summary, echo= F}
glimpse(profiles.orig)
df_status(profiles.orig)
head(profiles.orig)
```
The output above highlights the `profiles` tibble, with $\num{1002796}$ records and seven variables: the type-integer `userid`, `location`, and `lastlogin`, and the type-character `gender`, `memberfor`, `profileview`, and `age`).
Zeros and NAs are present in some variables---`location` or `age`, for example---but there are no infinite values.
The time tag in the `memberfor` variable was removed (see section \@ref(data-cleaning)) for being always equal to 00:00:00.

```{r ratings-summary, echo= F}
glimpse(ratings.orig)
df_status(ratings.orig)
head(ratings.orig)
```
Above, the `ratings` tibble, with $\num{8196077}$ instances and four variables (`userid`, `movieid`, `rating`, and `date`).
Similarly to the previous case, the time tag in `date` was removed (section \@ref(data-cleaning)).

Table \@ref(tab:variables) describes all variables contained in the three original tables of the data set.
Clearly, the type of some of variables is incorrect and inconvenient for analysis---`age`, `date`, and `gender`, just to name a few---and that was taken care of in section \@ref(data-cleaning).

Table: (\#tab:variables) List of variables present in the three original files from the Flixster data set.

Variable    |Type        |Description                   |Tibble
------------|------------|------------------------------|------
age         |character   |Age of user                   |profiles
date        |character   |Date in which user rated movie|ratings
gender      |character   |User gender                   |profiles
lastlogin   |integer     |Last login numerical tag      |profiles
location    |integer     |Location identifier of user   |profiles
memberfor   |character   |Member since date             |profiles
movieid     |integer     |Movie unique identifier       |movies
movieid     |integer     |Movie unique identifier       |ratings
moviename   |character   |movie name                    |movies
profileview |character   |Numerical tag of the user     |profiles
rating      |double      |Rating of movie by user       |ratings
userid      |integer     |User unique identifier        |profiles
userid      |integer     |User unique identifier        |ratings


# Exploratory data analysis and engineering {#edae}
The creation of a recommendation system requires the identification of the most important features involved in the prediction of the ratings.
With that goal in mind, we cleaned the data (section \@ref(data-cleaning)) and analysed statistically the variables (section \@ref(eda)) to understand them and the relationships between them.

Since **R** does not have a base function to calculate the mode, we created one, the `getmode` function.
It was useful in our statistical analysis and in the imputation of values in some of the variables.

```{r functions, eval= T}
# compute the mode
getmode= function(arr) {
  uniq.vals= unique(arr)
  uniq.vals[which.max(tabulate(match(arr, uniq.vals)))]
}
```

```{r raw-data, echo= F}
movies.raw= data.frame(movies.orig)
profiles.raw= data.frame(profiles.orig)
ratings.raw= data.frame(ratings.orig)
```

## Data cleaning {#data-cleaning}
We started by removing the time tag from the variables `date` and `memberfor`, as it was always equal to 00:00:00 and, thus, irrelevant for our analysis.

```{r clean-date, echo= F}
ratings.raw$date= ratings.raw$date %>% str_replace(" 00:00:00", "")
profiles.raw$memberfor= profiles.raw$memberfor %>% str_replace(" 00:00:00", "")
```

Then, we converted the variables `age` and `provileview` to integers, `gender` to a factor, and `memberfor` and `date` to dates.
```{r conversions, echo= F}
profiles.raw$age= as.integer(profiles.raw$age)
profiles.raw$profileview= as.integer(profiles.raw$profileview)
profiles.raw$gender= as.factor(profiles.raw$gender)
profiles.raw$memberfor= as.Date(profiles.raw$memberfor)
ratings.raw$date= as.Date(ratings.raw$date)
```

Several movie included strange characters in their names due to badly or poorly rendered ASCII codes.
Those were identified and replaced.
```{r str-replace, echo= F}
movies.raw$moviename= movies.raw$moviename %>%
  str_replace_all("&#233;", "é")
movies.raw$moviename= movies.raw$moviename %>%
  str_replace_all("&amp;", "&")
movies.raw$moviename= movies.raw$moviename %>%
  str_replace_all("&#\\d*;", "")

```

Finally, for the sake of personal taste and convenience, we converted the three main tables into tibbles.
```{r tibbles, echo= F}
movies= tbl_df(movies.raw)
profiles= tbl_df(profiles.raw)
ratings= tbl_df(ratings.raw)
```
A quick inspection allowed us to conclude that the `profilesview` and `age` variables were the same.
So, we decided to remove the former right away, even before a more in depth exploratory data analysis.
```{r remove-profileview, echo= F}
profiles= profiles %>% select(-"profileview")
```

Below is a summary of the three tables---respectively `movies`, `profiles`, and `ratings`---as they stood after the preliminary cleaning of the variables.
```{r summary-tibbles}
movies
profiles
ratings
```

## Statistical exploration of the variables {#eda}
All features contained in the three tibbles (`movies`, `profiles`, and `ratings`) were saved in standalone variables, to facilitate their statistical analysis.
Those variables are described in tab. \@ref(tab:variables-standalone).
It is worth noting that during the creation of the `gender` variable, all NAs were assigned the category "Other".

Table: (\#tab:variables-standalone) List of standalone variables created from the original features present in the three files from the Flixster data set, after type correction and preliminary data engineering.

Variable        |Type        |Description                   |Tibble
----------------|------------|------------------------------|------
age             |integer     |Age of user                   |profiles
dates           |date        |Date in which user rated movie|ratings
gender          |factor      |Gender of the user (*Female*, *Male*, and *Other*) |profiles
lastlogin       |integer     |Last login numerical tag      |profiles
location        |integer     |Location identifier of user   |profiles
memberfor       |date        |Member since date             |profiles
movieid.movies  |integer     |Movie unique identifier       |movies
movieid.ratings |integer     |Movie unique identifier       |ratings
moviename       |character   |movie name                    |movies
profileview     |integer     |Numerical tag of the user     |profiles
rating          |double      |Rating of movie by user       |ratings
userid.profiles |integer     |User unique identifier        |profiles
userid.ratings  |integer     |User unique identifier        |ratings



```{r variables}
age= profiles$age
dates= ratings$date
gender= fct_explicit_na(profiles$gender, "Other")
lastlogin= profiles$lastlogin
location= profiles$location
memberfor= profiles$memberfor #
movieid.movies= movies$movieid
movieid.ratings= ratings$movieid
moviename= movies$moviename
rating= ratings$rating
userid.profiles= profiles$userid
userid.ratings= ratings$userid
```

Understanding the structure of the data, the distribution of the variables, and the relationships between them is fundamental to build a solid model.
We therefore analysed each of the features present in tab. \@ref(tab:variables).

### Age
The variable `age` has a minimum of 12 years, a maximum of 113 years, and a median of 25 years.
The maximum is clearly an outlier.
The variable also contains more than $\num{255000}$ NAs, corresponding to approximately $25.5\,\%$ of all age values.
```{r summary=age}
summary(age) # min= 12; max= 113; NAs= 255618
idx.nas.age= which(is.na(age)) # 25.5% of all age values
```

Removing the NAs, we obtain a variance of $\num{107.5}$ years.
```{r age-clean}
age.clean= na.omit(age)
var(age.clean) # 107.5378
```
The skewness is positive, indicating a right-skewed distribution.
```{r age-skew}
skewness(age.clean) # 2.444335
```

We plotted the histogram and the box-plot of `ages` (fig. \@ref(fig:age-outliers)).
```{r age-outliers, fig.cap= "\\label{fig:age-outliers}Histogram (*left*) and boxplot (*right*) of the `age` variable. The distribution is right skewed and exihibits several outliers."}
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(age.clean,
  breaks= seq(round(min(age.clean)) - 1, round(max(age.clean)) + 1, by= 1),
  xlab= "Age (yrs)"
)
boxplot(age.clean,
  yaxt= "n",
  main= "Box-plot of age"
)
axis(2, las= 2)
```

Most of the individuals are between 18 and 30 years old, corresponding to more than $\num{250000}$ of Flixster's users.
The histogram highlights the right skewness of the distribution.
This is expected, since Flixster's customers were typically young.

We also plotted the histogram of `age` as a function of `gender` (fig. \@ref(fig:histo-age-gender)).
The vertical dashed lines represent respectively the first and 99.5^{th} percentile of the distribution of ages.

```{r histo-age-gender, fig.align= "center", fig.cap= "\\label{histo-age-gender}Histogram of the age of users as a function of their gender. The majority of Flixster users are women and men, with the first and 99.5$^{th}$ percentile between 14 and 70 years old."}
percentile.age= quantile(age, c(0.01, 0.9951), na.rm= T)
dfp.age=data.frame(value= percentile.age, percentile= c("1st", "99.5th"))
ggplot(data.frame(age= age, gender= gender)) +
  geom_histogram(
    aes(x= age, fill= gender),
    stat= "count",
    position= "dodge"
  ) +
  labs(x= "Age (yrs)", y= "Total", 
       title= "Distribution of users per age and gender"#, 
#       subtitle= "(right skewed distribution)"
  ) +
  geom_vline(
    data= dfp.age,
    aes(xintercept= value, colour= percentile),
    show.legend= T,
    linetype= "dashed") +
  theme_bw()
rm(percentile.age, dfp.age)
```

Ages bellow 14 and above 70 would be safe to be considered as outliers.
However, we only removed users with ages above 70 years old, the set of which corresponded to $0.5\,\%$ of all ages.
The histogram and box-plot of `ages` without outliers is represented in fig. \@ref(fig:age-no-outliers).

```{r age-out}
age.out= boxplot.stats(age.clean, coef= 3.9)$out
age.no.out.idx= !(age.clean %in% age.out)
age.no.out= age.clean[age.no.out.idx]
summary(age.no.out) # max= 71 (99.5% of values)
```

```{r age-no-outliers, fig.cap= "\\label{age-no-outliers}Histogram (*left*) and boxplot (*right*) of `ages` after removing the outliers."}
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(age.no.out,
  breaks= seq(round(min(age.no.out)) - 1, round(max(age.no.out)) + 1, by= 1),
  xlab= "Age (yrs)",
  main= "Histogram of age"
)
boxplot(age.no.out, outline= F, yaxt= "n")
axis(2, las= 2)
mtext(
  side= 3, line= 2, at= 1, cex= 1.2,
  expression(paste("Box-plot of age"))
)
mtext(side= 3, line= 1, at= 1, cex= 0.7, "Outliers removed")
```

### Dates and Memberfor {#dates-memberfor}
We detected three types of incorrect dates in the data set, both in the `date` and `memberfor` variables (respectively from the `ratings` and the `profiles` tibbles).
The first two types corresponded to dates either before the founding of Flixster (2006/01/20) or NA values---we detected dates as early as 1900/01/01 in `memberfor` and 1941/12/07 in `dates`, and 203 NAs in `memberfor` (no NAs in `dates`).
Regarding the NAs in `memberfor`, we simply removed the corresponding instances, since, on the one hand the total number of NAs was small, corresponding to $0.02\,\%$ of the total number of values, and, on the other hand, there was no way of estimating a reasonable date.
For the remainder of the wrong dates, we performed imputation, according to the following rules: (*i*) we made `memberfor` equal to the minimum rating date every time the former was after the latter, *i.e.*, when the membership date was after the first rating, and (*ii*) we replaced all dates before 2006/01/20 by Fixster's founding date.

The third type of wrong dates corresponded to dates in `dates` which were earlier than the registration date in Flixster (the date saved in the `memberfor` variable).
In those cases, we took the earliest date recorded in `dates` as the date for `memberfor`.
Since there are $\num{147612}$ unique user IDs in the tibble `ratings`, we obtained a "cleaned" `memberfor` variable with that number of dates.
We ended up with two arrays with dates between 2006/01/20 and 2009/11/17 (`dates` case) or 2009/11/01 (`memberfor` case), with no NAs.

```{r date-memberfor}
date.flixster= as.Date("2006-01-20")
idx.memberfor.wrong= which(profiles$memberfor < date.flixster) # 57722
profiles$memberfor[idx.memberfor.wrong]= date.flixster
memberfor= profiles$memberfor
idx.nas.memberfor= which(is.na(memberfor)) # 203
uids.memberfor.nas= profiles$userid[idx.nas.memberfor] # 203
```


```{r nas-memeberfor, eval= T}
# fill in NAs in memberfor with earliest rating date
# join profiles and ratings tables
usrats= ratings %>% left_join(profiles, by= "userid")
usrats$memberfor[is.na(usrats$memberfor)]= date.flixster
usrats= usrats %>% group_by(userid) %>% arrange(date) %>% slice(1L)
idcs= which(usrats$date < usrats$memberfor)
usrats$memberfor[idcs]= usrats$date[idcs]
memberfor= usrats$memberfor
member.date= tibble(userid= usrats$userid, memberfor= usrats$memberfor)
```
``` {r save-date-memberfor, echo= F, eval= F}
save(member.date, file= "../data/member.date.rdata")
save(memberfor, file= "../data/memberfor.rdata")
save(usrats, file= '../data/usrats.rdata')
```


```{r date-wrong, }
idx.date.wrong= which(ratings$date < date.flixster) # 2998
# sum(idx.date.wrong %in% idx.memberfor.wrong) # 35
ratings$date[idx.date.wrong]= date.flixster
dates= ratings$date
```


### Gender
The proportions of the three gender categories previously identified (*Female*, *Male*, and *Other*) were highlighted in a pie chart (see fig. \@ref(fig:pie-chart)).
The set of Flixster's users was comprised of $49\,\%$ of males, $44\,\%$ of females, and $7\,\%$ of other/unidentified genders.

```{r pie-chart, fig.align= "center", fig.height= 4, fig.width= 4, fig.cap= "\\label{pie-chart}Gender spread among Flixster users."}
n.gender= length(gender)
gender.woman= gender[gender == "Female"]
n.woman= length(gender.woman)
gender.woman.pct= round(n.woman / n.gender * 100)
gender.man= gender[gender == "Male"]
n.man= length(gender.man)
gender.man.pct= round(n.man / n.gender * 100)
gender.other= gender[gender == "Other"]
n.other= length(gender.other)
gender.other.pct= round(n.other / n.gender * 100)
gender.labels= c(
  paste('Women:', gender.woman.pct),
  paste('Men:',   gender.man.pct),
  paste('Other:', gender.other.pct))
gender.labels= paste0(gender.labels, '%')
gender.colours= c("#FA9FB5", "#74A9CF", "#2ECC71")
par(mfrow= c(1, 1), oma= c(0, 0, 0, 0))
pie3D(c(n.woman, n.man, n.other), theta= pi/3,
      labels= gender.labels, labelcex= 1.5,
      col= gender.colours,
      start= pi/4, explode= 0.08)
mtext("Gender spread", side= 3, line= -4, outer= T, cex= 2)

```

### Last login
Due to the lack of information about the data set, we do not know exactly what this variable represents.
We suspect, however, it corresponds to the total number of logins during a certain period of time (during the previous month or year) per user.
Assuming that is the case, most of the users had logged in to Flixster during that period of time between approximately 4 to 30 times.
The minimum of `lastlogin` is 0, meaning a user never logged in, and the
maximum is $\num{177278}$.
There are $\num{57925}$ NAs, corresponding to $5.7\,\%$ of all values.
The distribution is strongly right skewed, with several outliers lying far away from the median, *i.e.*, corresponding to number of occurrences several orders of magnitude above the median.
We removed the outliers by wiping out all values with frequencies above 46 (that kept $99\,\%$) of all the values.
The histogram and box-plot of the distribution with and without outliers are represented in figs. \@ref(fig:lastlogin-out) and \@ref(fig:lastlogin-no-out), respectively.

```{r results= "hide"}
idx.nas.lastlogin= which(is.na(lastlogin)) # 5.7% of all values
lastlogin= na.omit(lastlogin)
var(lastlogin) # 102829.2
skewness(lastlogin) # 217.3447
```

```{r lastlogin-out, fig.cap= "\\label{lastlogin-out}Histogram (*left*) and boxplot (*right*) of the variable `lastlogin`. Some outliers lie very far away from the median."}
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(lastlogin,
  breaks= seq(round(min(lastlogin)) - 1, round(max(lastlogin)) + 1),
  xlab= "Last login"
)
boxplot(lastlogin,
  yaxt= "n",
  main= "Box-plot of lastlogin"
)
axis(2, las= 2)
```
```{r lastlogin-no-out, fig.cap= "\\label{lastlogin-no-out}Histogram (*left*) and boxplot (*right*) of the variable `lastlogin` after removing the outliers."}
### remove outliers
lastlogin.out= boxplot.stats(lastlogin, coef= 20)$out
lastlogin.no.out.idx= !(lastlogin %in% lastlogin.out)
lastlogin.no.out= lastlogin[lastlogin.no.out.idx]
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(lastlogin.no.out,
  breaks= seq(round(min(lastlogin.no.out)) - 1, round(max(lastlogin.no.out))),
  xlab= "Last login",
  main= "Histogram of lastlogin"
)
boxplot(lastlogin.no.out, outline= F, yaxt= "n")
axis(2, las= 2)
mtext(
  side= 3, line= 2, at= 1, cex= 1.2,
  expression(paste("Box-plot of lastlogin"))
)
mtext(side= 3, line= 1, at= 1, cex= 0.7, "Outliers removed")

```

Since this variable did not seem to be relevant for any of our analyses, we decided to discard it.

### Location
This variable presented several NAs, corresponding to $0.02\,\%$ of all values.
The histogram (\@ref(fig:loca-out)) is characterised by a sharp spike at the value 0, with a difference of at least one order of magnitude to the remainder of the local maxima.
This might indicate that 0 corresponds to the most typical region the users belong to, or might be just an identifier of all users for whom the location is unknown (an outlier, in that case).
Since there is no information about the variables and `location` is a feature of integers, we decided to impute all NAs with the mode (the value 0).
After the imputation, `location` varied between 0 and $\num{1617}$.

```{r location}
idx.nas.location= which(is.na(location)) # ~0.02% of all values
loca= na.omit(location)
cat("Variance of `location`:", var(loca)) # 81802.41
cat("Skewness of `location`:", skewness(loca)) # 1.036804
## remove NAs
location[idx.nas.location]= 0
```

```{r loca-out, fig.cap= "\\label{loca-out}Histogram (*left*) and boxplot (*right*) of the `location` variable."}
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(loca,
  breaks= seq(round(min(loca)) - 1, round(max(loca)) + 1),
  xlab= "Location"
)
boxplot(loca,
  yaxt= "n",
  main= "Box-plot of location"
)
axis(2, las= 2)
```

We then looked to the distribution of the `location` values without outliers.
Zero and all values above $\num{1200}$ were placed in this category---the remainder of the set corresponded to approximately $99\,\%$ of the original values.
The new histogram and box-plot are represented in fig. \@ref(fig:loca-no-out).

```{r locatoin-no-out, include= F}
remove= c(0)
location= location[!(location %in% remove)]
location.out= boxplot.stats(location)$out
location.no.out.idx= !(location %in% location.out)
location.no.out= location[location.no.out.idx]
```

```{r loca-no-out, fig.cap= "\\label{loca-no-out}Histogram (*left*) and boxplot (*right*) of the `location` variable, after the removal of the outliers."}
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(location.no.out,
  breaks= seq(round(min(location.no.out)) - 1, round(max(location.no.out))),
  xlab= "Location",
  main= "Histogram of location"
)
boxplot(location.no.out, outline= F, yaxt= "n")
axis(2, las= 2)
mtext(
  side= 3, line= 2, at= 1, cex= 1.2,
  expression(paste("Box-plot of location"))
)
mtext(side= 3, line= 1, at= 1, cex= 0.7, "Outliers removed")
```

With outliers removed, we verify that most of the values are between 180 and 300.
However, similarly to what happened with `lastlogin`, the lack of information about this feature makes it useless in our analysis.
Therefore, we decided to removed it from the final data set.

### Movie ID
We can find two variables named `movieid` in the data set, one from the `movies` table, and another from the `ratings` table.
The former is composed of unique entries, one per film, while the latter has several instances corresponding to the same movie, one per rating.
That makes `movieid.ratings` larger than `movieid.movies` (respectively $\num{8196077}$ against $\num{66730}$ entries).
None of these variables present NAs.

Since the feature `movieid.movies` represents just the identification (ID) number of each film, there were no relevant statistics to compute.
Hence, we focused our attention in `movieid.ratings` and plotted its histogram (fig. \@ref(fig:movieid)).

```{r movieid, fig.cap= "\\label{movieid}Histogram of the movie ID, contained in the `ratings` tibble. There is a particular film with ID above 60000 with the most of ratings."}

hist(movieid.ratings,
  breaks= seq(round(min(movieid.ratings)) - 1, round(max(movieid.ratings)) + 1),
  xlab= "Movie ID (ratings)"
)
```
From the histogram, we can see that the range of the number of ratings encompasses four orders of magnitude, existing films with much more ratings than others (naturally).
In particular, there is a movie with an ID greater than $\num{60000 }$ with around $\num{35000 }$ ratings that stands out.

### Ratings
Finally, we looked at the `ratings` feature.
From the summary, the histogram, and the box-plot of the variable, we verify that: (*a*) the ratings range between 0.5 and 5.0; (*b*) the most common ratings are 3.0, 3.5, and 5.0; (*c*) the variance is equal to $\num{1.192404}$; and (*d*) the distribution is left skewed ($skew = -0.7054742$).
We were already expecting to find a left skewed distribution for `ratings`, since in a sufficiently large data set of this nature, most of the ratings will lie above the medium (it is expected to find a large number of users liking a substantially large subset of films and, hence, giving them high ratings).
The plots of the histogram and box-plot of `ratings` are illustrated in fig. \@ref(ratings).
```{r rating, echo= F}
summary(rating) # min= 0.5; max= 5.0
cat("Variance of `ratings`:", var(rating)) # 1.192404
cat("Skewness of `ratings`:", skewness(rating)) # -0.7054742
```
```{r ratings, fig.cap= "\\label{fig:ratings}Histogram (*left*) and boxplot (*right*) of the `ratings` variable. As expected for this kind of variable (when the data set is sufficiently large), the distribution is left-skewed." }
par(mfrow= c(1, 2), oma= c(0, 2, 3, 1))
hist(rating,
  breaks= seq(round(min(rating)) -0.5, round(max(rating)) +0.5, by= 0.5),
  xlab= "Ratings"
)
boxplot(rating,
  yaxt= "n",
  main= "Boxplot of ratings"
)
axis(2, las= 2)

```

## Data engineering
As mentioned previously, the variables `lastlogin` and `location`  were not needed for the context of this analysis, and so they were removed (the feature `profileview` had already been removed in the preliminary data analysis).

```{r profiles-remove, echo= F}
profiles= profiles %>%  select(-c(lastlogin, location))
```

The `gender` column in `profiles` was replaced by the updated `gender` standalone variable (including the "Other" gender), and only the instances with no NAs in the age were kept.
At the end, `profiles` was reduced to a $\num{747178} \times 3$ tibble, containing no NAs and with the relevant features `userid`, `gender`, and `age`.
```{r profiles-update-gender-memberfor-age, echo= F}
profiles$gender= gender
profiles= profiles %>% 
  filter(profiles$userid %in% member.date$userid)
profiles$memberfor= memberfor
profiles= profiles %>%
  filter(! profiles$age %in% profiles$age[is.na(profiles$age)])
profiles= profiles %>% 
  filter(profiles$age %in% age.no.out)
```

We then created two variables, `mean_ratings` and `total_ratings`, respectively corresponding to the average rating by each user and total number of ratings per user.
Those features were added to the `profiles` tibble.

```{r useratings-profiles-join, echo= F, cache= T}
user.ratings= ratings %>%
  group_by(userid) %>%
  summarise(
    mean.ratings.user= mean(rating),
    total.ratings.user= n()
  )
# join user.ratings with profiles
profiles.inner= profiles %>% 
  inner_join(user.ratings, by= "userid")
```

```{r save-profiles, eval= F}
sum(apply(profiles.inner, 1, anyNA)) # 0 NAs
 save(profiles.inner, file= "../data/profiles.inner.rdata")
```

A similar approach was used with the `movies` tibble, where two new columns were created containing the average rating per film (`mean_rating`) and the total number of ratings each movie got (`total_rating`).

```{r movie-ratings-join, echo= F, cache= T}
movie.ratings= ratings %>%
  group_by(movieid) %>%
  summarise(
    mean.ratings.movie= mean(rating),
    total.ratings.movie= n()
  )
## join movie.ratings with movies
movies.inner= movies %>% 
  inner_join(movie.ratings, by= "movieid")
```

```{r movies-save, eval= F}
sum(apply(movies.inner, 1, anyNA))
save(movies.inner, file= "../data/movies.inner.rdata")
```

Finally, we joined the three tables, in sequence, into a single tibble named "flixster".
In a general film recommender system, we would use *left joins* during this step, because users without ratings would still be eligible for recommendations based not on their rating history, but on similar user profiles (history of views, for example).
However, in the case at hands, the only record we have of users' activity is their rating history.
When it does not exist, *i.e.*, when a user has not made any rating, the instance will be useless for predictions.
The same reasoning applies for the films: if a movie has not been rated, it will be pointless for predictions.

Therefore, we opted for inner joins, keeping only the common values between the tables, thus eliminating users and films without any rating.

Three tibbles were created: one containing all columns (`flixster`), a smaller version containing the variables `userid`, `gender`, `age`, `movieid`, `moviename`, `rating`, and `age` (`flixster.small`), and a tiny version, containing the features `userid`, `movieid`, `rating`, and `date` (`flixster.tiny`).
The `ratings` and `profiles` tibbles were joined using the `userid` variable, to which the `movies` tibble was joined using the `movied` feature.

```{r flixster-sets, echo= F, cache= T}
flixster.inner= ratings %>% 
  inner_join(profiles.inner, by= "userid") %>% 
  inner_join(movies.inner, by= "movieid")

flixster= flixster.inner %>%
  select(
    userid, gender, age, memberfor, total.ratings.user, mean.ratings.user,
    movieid, moviename, rating, date, mean.ratings.movie, total.ratings.movie
  )

flixster.small= flixster %>% 
  select(
    userid, gender, age,
    movieid, moviename,
    rating, date
  )

flixster.tiny= flixster %>% 
  select(
    userid,
    movieid,
    rating,
    date
  )
```

```{r save-data-sets, eval= F}
sum(apply(flixster, 1, anyNA)) # 0 NAs, 6,131,346 rows
sum(apply(flixster.small, 1, anyNA)) # 0 NAs
sum(apply(flixster.tiny, 1, anyNA)) # 0 NAs

save(flixster, file= "../data/flixster.rdata")
save(flixster.small, file= "../data/flixster.small.rdata")
save(flixster.tiny, file= "../data/flixster.tiny.rdata")

remove(movies, profiles, ratings)
```


A preview of the `flixster` tibble is shown below.
```{r flixster}
flixster
```


## Data exploration
The `flixster` tibble contains $\num{108779}$ unique users, who have rated at least one film, during a time span of almost four years, between the 20^{th} January 2006 and the 17^{th} of November 2009.
The majority of the users rated only a few films---$68.3\,\%$ of the users rated up to 10 films---while a small number of users rated over $\num{1000}$ movies---995 users in total, corresponding to approximately $0.9\,\%$ of the total users.

```{r subsets-1, eval= F}
users.less.10.ratings= flixster[flixster$total.ratings.user <= 10, ] %>% 
  group_by(userid) %>% 
  summarise(n= n()) %>% 
  nrow()

users.less.10.ratings / length(unique(flixster$userid))

users.more.1000.ratings= flixster[flixster$total.ratings.user >= 1000, ] %>% 
  group_by(userid) %>% 
  summarise(n= n()) %>% 
  nrow()

users.more.1000.ratings / length(unique(flixster$userid))
```

```{r flixster-group-head}
flixster %>% 
  group_by(userid) %>% 
  summarise(n= n()) %>% 
  arrange(n) %>% 
  head()
```

Figure \@ref(fig:users-ratings) depicts the histogram of the number of ratings per user.
Most of the users, approximately $68.3\,\%$ of them, rated up to 10 films.

```{r users-ratings, fig.align= "center", fig.cap= "\\label{users-ratings}Histogram of the number of ratings. Approximatelly 68.3% of the users rated 10 films or less. The x-axis is in a log10 scale."}
flixster %>%
  group_by(userid) %>% 
  summarise(n= n()) %>% 
ggplot() +
  geom_histogram(
    aes(n),
    color= "white",
    binwidth= 0.2
  ) +
  scale_x_log10() + 
  ggtitle("Distribution of ratings per number of users") + 
  xlab("log10(Number of ratings)") +
  ylab("Number of users") + 
  theme_bw()
```

We created a heat-map of users *versus* movies for a sample of 100 unique users (see \@ref(fig:heat-map)).
As expected, the user-movie matrix is sparse, being the majority of cells empty.
Some films had more ratings than others, and some users were more active than others.

```{r heatmap, fig.align= "center", fig.height= 6, fig.width= 6, fig.cap= "\\label{heatmap}Heatmap of user *vs* movie created from a sample of unique user IDs. The matrix is sparse, with several empty cells. Some movies present more ratings, and some users are more active."}
users.samp= sample(unique(flixster$userid), 100)
set.seed(42)
flixster %>% filter(userid %in% users.samp) %>% 
  select(userid, movieid, rating) %>% 
  mutate(rating= 1) %>% 
  spread(movieid, rating) %>% 
  select(sample(ncol(.), 100)) %>% 
  as.matrix() %>% 
  t(.) %>% 
  image(1:100, 1:100, ., xlab= "Movie", ylab= "User")
abline(h= 0:100+0.5, v= 0:100+0.5, col= "grey")
title("Heat map of User x Movie")
```

Table \@ref(tab:top10) highlights the top 10 of most active users, *i.e.*, the top 10 users with the most ratings.
The most active user rated over $\num{30000}$ movies since December 2007, and the second most active user rated over $\num{24600}$ films since August 2007---these are two examples of users whose registration date in the platform (the `memberfor` variable) was posterior to the date of the first rating and, thus, that had to be corrected (see section \@ref(dates-memberfor)).
The first woman appearing in this top 10 occupies the fifth position in the table with $\num{7356}$ ratings since July 2009.
In terms of gender spread, this top 10 is perfectly balanced, with a 1-to-1 ratio of women to men.

Table: (\#tab:top10) List of the top 10 active users, in terms of ratings..

  |User ID |Gender |Age |Member for |Total number of ratings
--|--------|-------|----|-----------|-----------------------
1 |103006  |Male   |27  |2007-12-05 |30977
2 |211247  |Male   |36  |2007-08-09 |24622
3 |182127  |Male   |51  |2009-06-29 |9974
4 |458966  |Male   |22  |2009-01-03 |9134
5 |170822  |Female |63  |2009-07-14 |7356
6 |13466   |Female |32  |2009-07-23 |6973
7 |338577  |Female |41  |2008-09-15 |6148
8 |733571  |Female |35  |2006-01-20 |5216
9 |120742  |Male   |30  |2008-10-02 |5039
10|41389   |Female |35  |2009-07-01 |5013

The sample distribution of ratings per number of movies is represented by the histogram of fig. \@ref(fig:ratings-movies).
As expected, most of the films received a low number of ratings---typically up to approximately 100 ratings.

```{r ratings-movies, fig.cap= "\\label{ratings-movies}Histogram of ratings per number of movies. The x-axis is in a log10 scale. Most of the films received approximately up to 100 ratings."}
flixster %>% group_by(movieid) %>%
  summarise(n= n()) %>%
  ggplot(aes(n)) +
  geom_histogram(color= "white") +
  scale_x_log10() +
  ggtitle("Distribution of ratings per number of movies") +
  xlab("log10(Number of ratings)") +
  ylab("Number of movies") +
  theme_bw()
```

The top 10 most rated movies is presented in tab. \@ref(tab:top10-movies).
The most rated film in Flixster was "Transformers: Revenge of the Fallen", with $\num{34791}$ ratings.
"Shrek", an animated film, occupies the third position, with $\num{19916}$ classifications.

Table: (\#tab:top10-movies) List of the top 10 most rated movies.

  |Movie ID |Movie name                                         |Total number of ratings
--|---------|---------------------------------------------------|--------
1 |62530    |Transformers: Revenge of the Fallen                |34791
2 |42237    |Pirates of the Caribbean: Dead Mans Chest          |22817
3 |45119    |Shrek                                              |19916
4 |39384    |Pirates of the Caribbean: At Worlds End            |19079
5 |56915    |The Lord of the Rings - The Fellowship of the Ring |18381
6 |56916    |The Lord of the Rings - The Two Towers             |17950
7 |20644    |Harry Potter and the Prisoner of Azkaban           |17698
8 |20645    |Harry Potter and the Philosopher's Stone           |17612
9 |24251    |Harry Potter and the Chamber of Secrets            |17410
10|26656    |Ice Age                                            |16487
 
The histogram of ratings per date is plotted in fig. \@ref(fig:ratings-date).

```{r ratings-year, fig.cap= "\\label{ratings-year}Histogram of ratings per year. The year with the most ratings was 2007, with over 2,500,000 ratings."}
flixster %>%
  mutate(year= year(date)) %>%
  ggplot(aes(x= year)) +
  geom_histogram(color= "white", binwidth= 1) + 
  ggtitle("Rating distribution per year") +
  xlab("Year") +
  ylab("Number of ratings") +
  theme_bw()
```

```{r ratings-month, fig.cap= "\\label{ratings-month}Histogram of ratings per month. The month with the overall most ratings was June, with over 700,000 ratings."}
flixster %>%
  mutate(month= month(date, label= T)) %>% 
  mutate(year= year(date)) %>% 
  ggplot(aes(x= month, fill= year)) +
  geom_histogram(
    stat= "count",
    binwidth= 0.2,
    color= "white",
    position= "dodge"
  ) + 
  ggtitle("Rating distribution per month") +
  xlab("Month") +
  ylab("Number of ratings") +
  theme_bw()
```

```{r ratings-date, fig.cap= "\\label{ratings-date}Histogram of ratings per date. The x-axis is in a log10 scale. Most of the films received approximately up to 100 ratings."}
flixster %>%
  ggplot(aes(date)) +
  geom_histogram(
    color= "white",
    binwidth= 29.5) +
  ggtitle("Distribution of ratings per date") +
  xlab("Date") +
  ylab("Number of ratings") +
  theme_bw()
```

The year with the most activity in Flixster was 2007, followed by 2009.
We cannot identify seasonality in the data.
On the one hand, the peak of activity in 2007 coincide with the first half of the year, during and right after the two most important film awards happen (The Golden Globes in early January, and the Oscars in late February).
However, on the other hand, 2008 clearly does not follow that pattern.
In 2009, the number of ratings increased steadily until June, but started to decline rapidly after that, until the end of the data set.

Table \@ref(tab:dates-ratings) highlights the dates with more ratings.
On the 15^{th} of April 2008, "Star Wars: episode IV -- A New Hope" became the film most rated on a single day in Flixster, with 418 ratings.

Table: (\#tab:dates-ratings) List of film titles, sorted by date and by total number of ratings, in descending order.
```{r dates-ratings, eval= F}
flixster %>%
  group_by(date, moviename) %>%
  summarise(count = n()) %>%
  arrange(-count) %>%
  head(10)
```

Figure \@(fig:ratings-n) depicts the sample distribution of Flixster's ratings.
The most used classifications were 3 and above.
```{r ratings-n, fig.cap= "\\label{ratings-n}Histogram of ratings. Classifications 3 and above were the most popular."}
data.rating= flixster %>%
  group_by(rating) %>%
  summarise(n= n())
data.rating$rating= as.character(data.rating$rating)
data.rating %>% 
  ggplot() +
  geom_histogram(
    aes(x= rating, y= n),
    stat= "identity",
    color= "white"
  ) +
  ggtitle("Distribution of ratings") +
  xlab("Rating") +
  ylab("Number of ratings") +
  theme_bw()
```


## Data preparation
The data was further prepared for the recommender model.
The process consisted of the five following steps:

  1. Selection of relevant data;
  1. Building of the recommendation model;
  1. Normalisation of the data;
  1. Binarisation of the data;
  1. Train/test splitting of the data.

### Selection of relevant data
Due to time and mainly computer resources constraints, we decided to use a subset of the `flixster` tibble, which contained over eight million instances.
The subset was created using two criteria to select the most relevant data: the most active users, and the most rated films.
Initially, we considered users with 10 or more ratings, and films which had received classifications 100 or more times.
However, when creating the model based on the user-based collaborative filtering (IBCF), **RStudio** would repeatedly consume all the RAM of our computers and shut down.
Consequently, we increased the thresholds, so that users were classified as active if they had produced 50 or more ratings, and movies with less than 500 classifications were disregarded.
We ended up with a table of $\num{4752926}$ rows.

```{r flixster-u50m500, cache= T, eval= F}
flixster.u50m500= flixster %>% 
  filter(total.ratings.user > 50, total.ratings.movie > 500)

save(flixster.u50m500, file= "../data/flixster.u50m500.rdata")
```
Such selection of data yielded a data set with $\num{34464}$ users and $\num{5292}$ films, corresponding to a reduction of approximately $9\,\%$ in the total number of instances.

### Building of the recommendation model
We followed two approaches in order to create the recommender model: using *binary* and *non-binary* information on the users' ratings.
That came down to run two **R** instructions from the *recommenderlab* package:
```{r rec-models, echo= F}
# binary
rec.mod.bin= recommenderRegistry$get_entries(
  dataType= "binaryRatingMatrix"
)

# non-binary
rec.mod= recommenderRegistry$get_entries(
  dataType= "realRatingMatrix"
)
```

We further instantiate the recommender rating matrices.
```{r load-flixster, echo= F}
load("../data/flixster.u50m500.rdata")
FLIXST= flixster.u50m500

ratingmat= dcast(
  FLIXST,
  userid ~ movieid,
  value.var= "rating"
  )

ratingmat= as.matrix(ratingmat)
```



### Normalisation of the data
Normalising the ratings matrix is very important when preparing the data for the recommender system, since it allows to remove the rating bias and, therefore, to account for those users who systematically grade movies with high or low ratings.
We started to produce recommendations without normalising the data, that we planned to compare with similar recommendations obtained with normalised rating matrices.
However, we did not manage to run the code with the normalised data in the due time, so the results presented in the following section will contain only the recommendations obtained initially (*i.e.*, without normalisation).

The normalisation of the ratings matrix would have consisted in applying the `normalize` function of the *recommenderlab* package, as is summarised in the following instruction:
```{r normalisation, eval= F}
ratingmat= normalize(ratingmat)
```


### Binarisation of the data
Using the "realRatingMatrix" class from the *recommenderlab* package, we created a real-valued sparse rating matrix, from which we generated a binary version of the rating matrix, using the `binarize` instruction from the same package.
Basically, `binarize` created a matrix belonging to the "binaryRatingMatrix" class by setting all ratings equal to or larger than 0.5 to 1, and all others to 0.
```{r sparse-binary, echo= F}
# convert rating matrix to recommenderlab sparse matrix
ratingmat= as(ratingmat, "realRatingMatrix")

# create binary rating matrix
ratingmat.bin= binarize(ratingmat, minRating= 0.5)
ntop= 10 # number of top movies to recommend to each user
```


### Train/test splitting of the data
We split the data set into two pieces, in a 7-to-3 ratio: the *train* set, containing $70\,\%$ of the data, and the *test* set, with the remainder $30\,\%$.
The former was used to train the models, while the latter was used to simulate "fresh" data to evaluate the performance of the models.

Both the training and the testing sets were generated from the rating matrices, so we ended up with four sets: one train-test pair for the binary approach, and another train-test pair for the no-binary approach.
The split resulted in *recomenderlab*'s structures of class "binaryRatingMatrix" (binary case) and class "realRatingMatrix" (no binary case).
The train sets consisted of $\num{12122} \times \num{2540}$ matrices with $\num{3335518}$ ratings, and the test sets to $\num{5210} \times \num{2540}$ rating matrices with $\num{1434740}$ ratings.
```{r}
set.seed(42)
idx_train_test= sample(
  c(TRUE, FALSE),
  size= nrow(ratingmat),
  replace= T,
  prob= c(0.7, 0.3)
)

train.nobin= ratingmat[  idx_train_test, ]
test.nobin=  ratingmat[! idx_train_test, ]

train.bin= ratingmat.bin[  idx_train_test, ]
test.bin=  ratingmat.bin[! idx_train_test, ]
```
The split resulted in a train set with $\num{4291942}$ rows, and a test set with $\num{1839404}$ rows.


# Recommendation engines
The goal of this section was to implement systems that would deliver relevant results, *i.e*, effective recommendations to Flixster's users.

Three recommender methods were applied to both the binary and non-binary approaches: *item-based collaborative filtering* (IBCF), *user-based collaborative filtering* (UBCF), and *popular*.

The IBCF and UBCF methods take into account the information about the users and the inherent collaboration between them to obtain recommendations of items.
While in the former the recommendations are based on the similarity between items, in the latter the recommendations are performed on a neighbourhood of users that share similar tastes.
We used the Cosine distance function (default in the *recommenderlab* package) for both.

The popular method simply recommends the most popular films, based on the number of ratings they have received.

In the following sections, we will present the code implemented for all of those methods applied in both the binary and non-binary cases, and the outputs of their application on the recommendation of 10 films to the first user of the `flixster.u50m500` table.


## Binary approach
### IBCF
```{r rec-ibcf-bin, cache= T, eval= F}
rec.mod.bin$IBCF_binaryRatingMatrix$parameters
rec.mod.ibcf.bin= Recommender(data= train.bin, method= "IBCF")
rec.mod.ibcf.bin.pred= predict(
  object= rec.mod.ibcf.bin,
  newdata= test.bin,
  n= ntop
)

# recommendations for the first user
rec.ibcf.bin.user.1= rec.mod.ibcf.bin.pred@items[[1]]
movies.ibcf.bin.user.1= rec.mod.ibcf.bin.pred@itemLabels[rec.ibcf.bin.user.1]
movies.rec.ibcf.bin= movies.ibcf.bin.user.1
for (i in 1:ntop) {
  movies.rec.ibcf.bin[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.ibcf.bin.user.1[i])$moviename
    )
}
movies.rec.ibcf.bin
save(movies.rec.ibcf.bin, file= "../data/movies.rec.ibcf.bin.rdata")
```

```{r load-rec-ibcf-bin, echo= F}
load("../data/movies.rec.ibcf.bin.rdata")
```

The recommendations obtained for the first user are presented in tab. \@ref(tab:ibcf-bin).

Table: (\#tab:ibcf-bin) List of the 10 recommended films to user #1, obtained with the IBCF method using a binary approach.

n |Movie name
--|-----------------
1 |"The Lion King"
2 |"Men in Black"
3 |"Mrs. Doubtfire"
4 |"Home Alone"
5 |"The Mask"
6 |"Jumanji"
7 |"Jurassic Park"
8 |"Toy Story 2"
9 |"A Bugs Life"
10|"Dr. Dolittle"

 

### UBCF
```{r rec-ubcf-bin, cache= T, eval= F}
rec.mod.bin$UBCF_binaryRatingMatrix$parameters
rec.mod.ubcf.bin= Recommender(data= train.bin, method= "UBCF")
rec.mod.ubcf.bin.pred= predict(
  object= rec.mod.ubcf.bin,
  newdata= test.bin,
  n= ntop
)

# recommendations for the first user
rec.ubcf.bin.user.1= rec.mod.ubcf.bin.pred@items[[1]]
movies.ubcf.bin.user.1= rec.mod.ubcf.bin.pred@itemLabels[rec.ubcf.bin.user.1]
movies.rec.ubcf.bin= movies.ubcf.bin.user.1
for (i in 1:ntop) {
  movies.rec.ubcf.bin[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.ubcf.bin.user.1[i])$moviename
    )
}
movies.rec.ubcf.bin
save(movies.rec.ubcf.bin, file= "../data/movies.rec.ubcf.bin.rdata")
```

```{r load-ubcf-bin, echo= F}
load("../data/movies.rec.ubcf.bin.rdata")
```

The ten recommended movies are indicated in tab. \@ref(tab:ubcf-bin).

Table: (\#tab:ubcf-bin) List of the 10 recommended films to user #1, obtained with the UBCF method using a binary approach.

n |Movie name
--|-----------------
1 |"The Lion King"
2 |"Spider-Man 3"
3 |"Forrest Gump"
4 |"Halloween"
5 |"The Brave One"
6 |"Sydney White"
7 |"Mr. Beans Holiday"
8 |"War (Rogue Assassin)"
9 |"Lucky You"
10|"The Ex"


## Popular
```{r rec-pop-bin, cache= T, eval= F}
rec.mod.bin$POPULAR_binaryRatingMatrix$parameters
rec.mod.pop.bin= Recommender(data= train.bin, method= "POPULAR")
rec.mod.pop.bin.pred= predict(
  object= rec.mod.pop.bin,
  newdata= test.bin,
  n= ntop
)

# recommendations for the first user:
rec.pop.bin.user.1= rec.mod.pop.bin.pred@items[[1]]
movies.pop.bin.user.1= rec.mod.pop.bin.pred@itemLabels[rec.pop.bin.user.1]
movies.rec.pop.bin= movies.pop.bin.user.1
for (i in 1:ntop){
  movies.rec.pop.bin[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.pop.bin.user.1[i])$moviename
    )
}
movies.rec.pop.bin
save(movies.rec.pop.bin, file= "../data/movies.rec.pop.bin.rdata")
```

```{r load-pop-bin, echo= F}
load("../data/movies.rec.pop.bin.rdata")
```

The ten movies recommended for the first user by this method are compiled in tab. \@ref(tab:pop-bin).

Table: (\#tab:pop-bin) List of the 10 recommended films to user #1, obtained with the Popular method using a binary approach.

n |Movie name
--|-----------------
1 |"The Lion King"
2 |"Men in Black"
3 |"Home Alone"
4 |"The Mask"
5 |"Mrs. Doubtfire"
6 |"Jurassic Park"
7 |"Forrest Gump"
8 |"X-Men"
9 |"The Fast and the Furious"
10|"Jumanji"


## Non-binary approach
### IBCF
```{r rec-ibcf-nonbin, cache= T, eval= F}
rec.mod$IBCF_realRatingMatrix$parameters
rec.mod.ibcf= Recommender(data= train.nobin, method= "IBCF")
rec.mod.ibcf.pred= predict(
  object= rec.mod.ibcf,
  newdata= test.nobin,
  n= ntop
)

# recomendations for the first user
rec.ibcf.user.1= rec.mod.ibcf.pred@items[[1]]
movies.ibcf.user.1= rec.mod.ibcf.pred@itemLabels[rec.ibcf.user.1]
movies.rec.ibcf= movies.ibcf.user.1
for (i in 1:ntop) {
  movies.rec.ibcf[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.ibcf.user.1[i])$moviename
    )
}
movies.rec.ibcf
save(movies.rec.ibcf, file= "../data/movies.rec.ibcf.rdata")
```

```{r load-ibcf-nonbin, echo= F}
load("../data/movies.rec.ibcf.rdata")
```

The films recommended for the first user are indicated in tab. \@ref(tab:ibcf-non-bin).

Table: (\#tab:ibcf-non-bin) List of the 10 recommended films to user #1, obtained with the IBCF method using a non-binary approach.

n |Movie name
--|-----------------
1 |"batteries not included"
2 |"88 Minutes"
3 |"8 Seconds"
4 |"A Nightmare on Elm Street 2 - Freddys Revenge"
5 |"A Walk in the Clouds"
6 |"Above the Law"
7 |"Air Bud Spikes Back"
8 |"Adaptation"
9 |"Adventures in Babysitting"
10|"Aliens vs. Predator: Requiem (AVP 2)"


### UBCF
```{r rec-ubcf-nonbin, cache= T, eval= F}
rec.mod$UBCF_realRatingMatrix$parameters
rec.mod.ubcf= Recommender(data= train.nobin, method= "UBCF")
rec.mod.ubcf.pred= predict(
  object= rec.mod.ubcf,
  newdata= test.nobin,
  n= ntop
)

# recommendations for the first user
rec.ubcf.user.1= rec.mod.ubcf.pred@items[[1]]
movies.ubcf.user.1= rec.mod.ubcf.pred@itemLabels[rec.ubcf.user.1]
movies.rec.ubcf= movies.ubcf.user.1
for (i in 1:ntop) {
  movies.rec.ubcf[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.ubcf.user.1[i])$moviename
    )
}
movies.rec.ubcf
save(movies.rec.ubcf, file= "../data/movies.rec.ubcf.rdata")
```

```{r load-ubcf-nonbin, echo= F}
load("../data/movies.rec.ubcf.rdata")
```

The table with the recommendations for the first user in the `flixster.u50m500` tibble are presented in tab. \@ref(tab:ubcf-non-bin).

Table: (\#tab:ubcf-non-bin) List of the 10 recommended films to user #1, obtained with the UBCF method using a non-binary approach.

n |Movie name
--|-----------------
1 |"101 Dalmatians"
2 |"102 Dalmatians"
3 |"12 Angry Men (Twelve Angry Men)"
4 |"15 Minutes"
5 |"21 Grams"
6 |"28 Weeks Later..."
7 |"3 Ninjas"
8 |"*batteries not included"
9 |"101 Dalmatians (One Hundred and One Dalmatians)"
10|"12 Rounds"


### Popular
```{r rec-pop-nonbin, cache= T, eval= F}
rec.mod$POPULAR_realRatingMatrix$parameters
rec.mod.pop= Recommender(data= train.nobin, method= "POPULAR")
rec.mod.pop.pred= predict(
  object= rec.mod.pop,
  newdata= test.nobin,
  n= ntop
)

# recommendations for the first user:
rec.pop.user.1= rec.mod.pop.pred@items[[1]]
movies.pop.user.1= rec.mod.pop.pred@itemLabels[rec.pop.user.1]
movies.rec.pop= movies.pop.user.1
for (i in 1:ntop){
  movies.rec.pop[i]= as.character(
    subset(
      FLIXST,
      FLIXST$movieid == movies.pop.user.1[i])$moviename
    )
}
movies.rec.pop
save(movies.rec.pop, file= "../data/movies.rec.pop.rdata")
```

```{r load-pop-nonbin, echo= F}
load("../data/movies.rec.pop.rdata")
```

Finally, the movies recommendations for the first user of the data set are compiled in tab. \@ref(tab:pop-non-bin).

Table: (\#tab:pop-non-bin) List of the 10 recommended films to user #1, obtained with the Popular method using a non-binary approach.

n |Movie name
--|-----------------
1 |"Charlottes Web (1973)"
2 |"Hana"
3 |"13 Ghosts (1960)"
4 |"Gone in 60 Seconds (1974)"
5 |"Inglorious Bastards (Deadly Mission) (Counterfeit Commandos)"
6 |"Casper (1995)"
7 |"Reindeer Games (Deception)"
8 |"Iron Man (Ironman)"
9 |"Beauty and the Beast (1992)"
10|"Barb Wire"


At the end, all models were saved for future reference.
```{r save-models, eval= F}
# binary case
save(
  rec.mod.bin,
  ratingmat.bin,
  train.bin, test.bin,
  rec.mod.ibcf.bin, rec.mod.ibcf.bin.pred, movies.rec.ibcf.bin,
  rec.mod.ubcf.bin, rec.mod.ubcf.bin.pred, movies.rec.ubcf.bin,
  rec.mod.pop.bin, rec.mod.pop.bin.pred, movies.rec.pop.bin,
  file= "../data/recommender-system-binary.rdata"
)

# non-binary case
save(
  rec.mod,
  ratingmat,
  train.nobin, test.nobin,
  rec.mod.ibcf, rec.mod.ibcf.pred, movies.rec.ibcf,
  rec.mod.ubcf, rec.mod.ubcf.pred, movies.rec.ubcf,
  rec.mod.pop, rec.mod.pop.pred, movies.rec.pop,
  file= "../data/recommender-system-no-binary.rdata"
)
```


# Evaluation of the recommendation engines
We evaluated the performance of the methods implemented in the previous section by means of *k-fold cross-validation* (kCF).
In this approach, the data is split into *k* blocks, one of which is set aside as the test set and used to compute the accuracy.
The process is repeated *k* times, using a different fold as the test data in each run.
We used a 4-fold CV, thus obtaining four sets of the same size ($\num{12630}$ ratings in both the binary and non-binary approaches).

The code for the binary and the non-binary approaches is similar.
We started by creating a list of the models, and to define a set of parameters:

- `TOP.N`: the top *N* recommendations;
- `ITEMS`: number of films to generate recommendations;
- `RAT.THRESH`: minimum rating to be considered as a good option;
- `N.FOLDS`: number of folds/samples to run to run the evaluation to (for the cross-validation).

```{r eval-params, echo= F}
models= list(
  ibcf= list(name= "IBCF"),
  ubcf= list(name= "UBCF"),
  pop= list(name= "Popular")
)

TOP.N= c(1, 2, 5, seq(10, 100, 10)) # top N recommendations
ITEMS= 1 # number of films to generate recommendations
RAT.THRESH= 3 # minimum rating to be considered a good option
N.FOLDS= 4 # number of folds/samples to run evaluation to (for the CV)
```

Then, we selected the most relevant data using the same criteria as before: users with more than 50 ratings, and films which have been rated more than 500 times.
The resulting selection yields two $\num{16841} \times \num{2066}$ rating matrices respectively of class "binaryRatingMatrix" and "realRatingMatrix", with $\num{4559716}$ ratings each.

```{r relevant-ratings, cache= T, echo= F}
ratings.bin= ratingmat.bin[
  rowCounts(ratingmat.bin) > 50,
  colCounts(ratingmat.bin) > 500
]

ratings.nobin= ratingmat[
  rowCounts(ratingmat) > 50,
  colCounts(ratingmat) > 500
]
```

We applied the 4-fold CV, and evaluated the list of recommender models:
```{r 4cv-bin, echo= F, cache= T, eval= F}
eval.bin= evaluationScheme(data= ratings.bin,
                           method= "cross-validation",
                           k= N.FOLDS,
                           given= ITEMS,
                           goodRating= RAT.THRESH)
```
```{r results-bin, eval= F, echo= F}
results.bin= evaluate(x= eval.bin,
                      method= models,
                      n= TOP.N )
results.bin
```

We got four sets of size $\num{12630}$.

```{r evals-size-bin, echo= F, cache= T}
load("../data/eval.bin.rdata")
load("../data/results.bin.rdata")
evals.bin.size= sapply(eval.bin@runsTrain, length)
```

We collected the training data for the runs, the known ratings used for the predictions in the test data, and the ratings used for evaluation of the test data, and plotted the histogram of the training and testing data corresponding to the distribution of ratings per user.

```{r train-unknown-histo, echo= F}
eval.bin.train= getData(eval.bin, "train")

# known ratins used for prediction for test data
eval.bin.known= getData(eval.bin, "known")

# ratings used for evaluation for test data
eval.bin.unknown= getData(eval.bin, "unknown")

eval.bin.train.df= data.frame(x= rowCounts(eval.bin.train), type= "train")
eval.bin.known.df= data.frame(x= rowCounts(eval.bin.known), type= "known")
eval.bin.unknown.df= data.frame(x= rowCounts(eval.bin.unknown), type= "unknown")

evals.bin.all= rbind(
  eval.bin.train.df,
  eval.bin.known.df,
  eval.bin.unknown.df
)
evals.bin= rbind(
  eval.bin.train.df,
  eval.bin.unknown.df
)

ggplot(
  evals.bin,
  aes(x= x, fill= type)
) +
  geom_histogram(
    binwidth= 20,
    alpha= 0.5
  ) +
  labs(
    x= "Number of ratings per user",
    y= "Count",
    title= "Data used for the runs"
  ) +
  theme_bw()
```

As expected, the number of users decrease with the number of ratings, *i.e.*, less and less users rate a lot of films.

Then, using the `getConfusionMatrix` from the *recommenderlab* package, we created confusion matrices for each method, and summed up the indices of all metrics in order to have an overall picture of all the folds.

```{r confusion-bin, echo= F}
cm.ibcf.bin= getConfusionMatrix(results.bin$ibcf)
cm.ubcf.bin= getConfusionMatrix(results.bin$ubcf)
cm.pop.bin=  getConfusionMatrix(results.bin$pop)

# condense results of all folds
columns.to.sum= c("TP", "FP", "FN", "TN", "precision", "recall", "TPR", "FPR")
cm.sum.ibcf.bin= Reduce(
  "+",
  getConfusionMatrix(results.bin$ibcf)
)[, columns.to.sum]
cm.sum.ubcf.bin= Reduce(
  "+",
  getConfusionMatrix(results.bin$ubcf)
)[, columns.to.sum]
cm.sum.pop.bin= Reduce(
  "+",
  getConfusionMatrix(results.bin$pop)
)[, columns.to.sum]

```

Finally, we plotted the ROC curves and the precision/recall graphs.

```{r roc-bin, echo= F}
plot(
  results.bin,
  lw= 3,
  annotate= T,
  legend= "topleft",
  main= "ROC curve"
)

plot(
  results.bin,
  lw= 3,
  annotate= T,
  "prec/rec",
  legend= "topright",
  main= "Precision-Recall"
)
```

From the ROC curve and the corresponding *area under the curves* (AUCs), and from the precision-recall curve, we conclude that the best performing method for recommendation of Flixster's films is Popular, since this method attains the highest values for ROC, AUC, and precision-recall.

We applied the same procedure for the non-binary approach, and we obtained similar results, having the Popular method attained the best performance out of the three methods.
For reference, we indicate the corresponding code in a single chunk, without evaluating it.

```{r non-binary, echo= F, eval= F}
eval.nobin= evaluationScheme(data= ratings.nobin,
                             method= "cross-validation",
                             k= N.FOLDS,
                             given= ITEMS,
                             goodRating= RAT.THRESH)

results.nobin= evaluate(x= eval.nobin,
                        method= models,
                        n= TOP.N )
results.nobin

evals.nobin.size= sapply(eval.nobin@runsTrain, length)

# training data for the runs
eval.nobin.train= getData(eval.nobin, "train")

# known ratins used for prediction for test data
eval.nobin.known= getData(eval.nobin, "known")

# ratings used for evaluation for test data
eval.nobin.unknown= getData(eval.nobin, "unknown")

eval.nobin.train.df= data.frame(
  x= rowCounts(eval.nobin.train),
  type= "train"
)
eval.nobin.known.df= data.frame(
  x= rowCounts(eval.nobin.known),
  type= "known"
)
eval.nobin.unknown.df= data.frame(
  x= rowCounts(eval.nobin.unknown),
  type= "unknown"
)

evals.nobin.all= rbind(
  eval.nobin.train.df,
  eval.nobin.known.df,
  eval.nobin.unknown.df
)
evals.nobin= rbind(
  eval.nobin.train.df,
  eval.nobin.unknown.df
)

ggplot(
  evals.nobin,
  aes(x= x, fill= type)
) +
  geom_histogram(
    binwidth= 20,
    alpha= 0.5
  ) +
  labs(
    x= "Number of ratings per user",
    y= "Count",
    title= "Data used for the runs"
  ) +
  theme_bw()


# confusion matrices
cm.ibcf.nobin= getConfusionMatrix(results.nobin$ibcf)
cm.ubcf.nobin= getConfusionMatrix(results.nobin$ubcf)
cm.pop.nobin=  getConfusionMatrix(results.nobin$pop)

# condense results of all folds
columns.to.sum= c("TP", "FP", "FN", "TN", "precision", "recall", "TPR", "FPR")
cm.sum.ibcf.nobin= Reduce(
  "+",
  getConfusionMatrix(results.nobin$ibcf)
)[, columns.to.sum]
cm.sum.ubcf.nobin= Reduce(
  "+",
  getConfusionMatrix(results.nobin$ubcf)
)[, columns.to.sum]
cm.sum.pop.nobin= Reduce(
  "+",
  getConfusionMatrix(results.nobin$pop)
)[, columns.to.sum]


plot(
  results.nobin,
  lwd= 3,
  annotate= T,
  legend= "topleft",
  main= "ROC curve"
)

plot(
  results.nobin$pop,
  col= "green",
  lwd= 3,
  annotate= T,
  "prec/rec",
  #legend= "topright",
  main= "Precision-Recall"
)
```

The time needed to run the code for each of the approaches (binary and non-binary) was large in our machines.
For instance, the evaluation of the recommendation engines took approximately three hours to complete.

In an attempt to reduce the time of execution, we repeated the whole process for a smaller data set, containing uniquely the variables `userid`, `movieid`, `moviename`, and `rating`---we do not reproduce the code here, as it is virtually the same as the one we presented in the previous sections, and the results are analogous.

However, we realised that the time of execution was similar to the previous approaches.
Therefore, the solution would be to remove even more rows from the data set, using stronger restrictions (for example, keeping only users with 500 or more ratings, and films with over 1000 ratings).

Another approach would be to apply stratified sampling, in order to extract a sample of records with the highest statistical significance possible, keeping the original multivariate histogram as faithfull as possible.
This was left as future work, since we had already run out of time.



# Association rules
We tried to build a recommendation system based on association-rule mining techniques, by applying the *Apriori* algorithm.
Given the data set, the goal was to find the films that are associated with each other.
This would give us the opportunity to understand associations between the movies.

We did two main attempts to get association rules out of the Flixster data set.
In the first one, before applying the Apriori algorithm, we transformed the data set to binary values, where 1 represents a positive rating, and 0 represents a negative one or no rating at all.
The rating threshold was 3, *i.e.*, all ratings bellow 3 were classified as 0, and all equal or above 3 were classified as 1.
We used the `binarize()` function from the *recommenderlab* package for that task.

```{r binarise-apriori, echo= F, cache= T}
load("../data/ratingmat.go.nobin.rdata")
# binarize into a binaryRatingMatrix with all 3+ rating as 1
rating.apr= binarize(ratingmat.go.nobin, minRating= 3)
```

Since the Apriori algorithm expects a matrix as input rather than an object of class "binaryRatingMatrix", we converted the previous object to the matrix format.

```{r apriori-convert-matrix, echo= F, cache= T}
# convert rating.apriori to matrix format
rating.mat.apr= as(rating.apr, "matrix")
```

The output was a matrix of booleans, which we converted to a matrix of ones and zeros:

```{r covert-1-0, echo= F, cache= T}
# convert cells of rating.mat.apr to 1 and 0
rating.mat.apr.num= 1*rating.mat.apr
#save(rating.mat.apr.num, file= "../data/rating.mat.apr.num.rdata")
```

We passed the parameters `support` and `confidence` to the algorithm.
The *support* tells us the fraction of transactions that contain an itemset.
It measures how often a rule should occur in the data set.
The *confidence* measures the strength of the rule.
We initially tried a support of 0.5 and a confidence of 0.8 in order to keep only meaningul rules.
We obtained 13 rules, but they were not meaningful, since some of them were empty, while in others the *right-hand-side* was always equal to "{userid}"---this might indicate a flaw in our algorithm.
As the number of returned rules was small and not meaningul, we relaxed the support and confidence thresholds to 0.3 and 0.7, respectively.

```{r rules, cache= T}
params.apr= list(
  supp= 0.3,
  conf= 0.7
)

# create rules
rules= apriori(data= rating.mat.apr.num, parameter= params.apr)

arules::inspect(rules)
```

The `rules` object has all the film associations that were extracted and mined from the data set.
With these parameters, 1408 movies association rules were extracted, in total.
A subset of those is indicated in tab. \@ref(tab:rules).

Table: (\#tab:rules) Sample of the inspection of the rules generated with the *Apriori* algorithm on the Flixster data set. Some of the rules are not meaningul, as they are empty or point to "userid", instead of a value of `movieid` (this is an indication of a flaw in our algorithm).

n  |lhs     |    |rhs     |support   |confidence | coverage |lift    |count
---|--------|----|--------|----------|-----------|----------|-------=|-----
1  |{}      | => |{userid}|1.00000000|1.000000000|1.00000000|1.000000|17332
2  |{19787} | => |{userid}|0.3122548 |1.0000000  |0.3122548 |1.000000| 5412
...|...     |... |...     |...       |...        |...       |...     |...
21 |{20642} | => |{24251} |0.3071775 |0.7397527  |0.4152435 |1.460462| 5324
22 |{20642} | => |{20645} |0.3103508 |0.7473947  |0.4152435 |1.468523| 5379
...|...     |... |...     |...       |...        |...       |...     |...
125|{30936} | => |{45119} |0.3231595 |0.7933428  |0.4073390 |1.305690| 5601



# Conclusions and prospects
We analysed the Flixster data set and we created recommender systems based on a binary and non-binary approach, applying the *item-based confident frequency*, the *user-based confident frequency*, and the *popular* methods, and association rules.

The number of records in the original data set was reduced by approximately $22\,\%$, by applying restrictions on the number classifications produced by users and on the number of films' ratings.
This was an attempt to, on the one hand, to make the data set more relevant and, on the other hand, to reduce the code's execution time.
While the relevance of the data was indeed increased, the time of excecution did not change, and other approaches needed to be tried, such as using stronger restrictions on the ratings per user and per film, or applying stratified sampling---it would be interesting to compare the recommendations obtained with any of these approaches with the ones we presented in this report.

For each of the first three aforementioned methods, we managed to recommend 10 films for a randomly chosen user (I picked the first in the data set) in both the binary and non-binary approaches.
Out of the three, the method which attained the best score in the ROC curves, the AUC, and in the precision-recall plots was the *popular* recommender system.
Since this method simply recommends films based on their ratings, this result becomes intersting in the context of human behaviour.
In fact, it is indicative that people tend to search for and wath the most popular films, instead of searching for others more similar to previous ones they have seen and enjoyed---this would be an interesting subject for further analysis.

We were able to produce association rules out of the data set, by setting values for the support and the confidence.
However, out of the hundreds generated, not all of them were meaningful, as by inspection we could spot empty fields and senseless right-hand sides.

This ended up to be a very challenging assignment, not so much because of the nature of the problem, but mostly because of the limitations of our computers.
The code took too long to finish, sepcially when generating non-binary UBCF recommendations and when comparing the models.
We feel we could have done a better job, and some of the tasks initially programmed were not fulfilled, such as obtain recommendations using a normalised data set, or try hybrid recommender systems.
These are fields we are keen to explore in a future opportunity.

# References {-}
In addition to the references highlighted within the report, we got inspiration from other sources, such as:

- [Ivamoto, V., 2019, *Movie Recommendation System in R*](https://rstudio-pubs-static.s3.amazonaws.com/558509_39f03d893ae44ceb94ed858d139b8741.html#24_modeling): for the EDA;
- [Novikova, J., 2016, *Building a Movie Recommendation System*](https://rstudio-pubs-static.s3.amazonaws.com/191386_f750ed5a99f1417da351f86b6d8b87ab.html): for the evaluation and comparison of the models;
- Liu, B., 2011, *Web Data Mining*, Springer: for main concepts;
- Ribeiro, R., 2020, *Notes on Data  Mining II / Advanced Topics in Data Science*: for concepts, ideas, and general guidance.